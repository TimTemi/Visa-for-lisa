{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a51514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sbs\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa33229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "def load_csv(file):\n",
    "    return pd.read_csv(file)\n",
    "    \n",
    "data = load_csv('Visa_For_Lisa_Loan_Modelling.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6747e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewing data info\n",
    "def view_data_info(data):\n",
    "    print(\"Data Dimension: \", data.shape)\n",
    "    print(\"Data Types: \", data.dtypes)\n",
    "    print(\"first 20 rows: \")\n",
    "    print(\"\\n\")\n",
    "    print(data.head(20))\n",
    "    print(\"Statistics\")\n",
    "    print(\"\\n\")\n",
    "    print(data.describe())\n",
    "view_data_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44724e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_data(data):\n",
    "    columns = data.columns\n",
    "    \n",
    "    #check for empty columns\n",
    "    empty_columns = []\n",
    "    for all in columns:\n",
    "        if data[all].isna().sum() > 0:\n",
    "            empty_columns.append(all)\n",
    "    \n",
    "    if len(empty_columns) > 0:\n",
    "        new_data = data.dropna(axis=0)\n",
    "    else:\n",
    "        new_data=data.drop(columns=['Personal Loan'])\n",
    "        new_data.insert(13, 'Personal Loan',data['Personal Loan'])\n",
    "        print(new_data.isnull().mean()) #there are no missing data\n",
    "\n",
    "        print(new_data['ID'].is_unique)\n",
    "        new_data.set_index('ID')\n",
    "        return new_data\n",
    "    \n",
    "data = cleaning_data(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5139282e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_histograms(data):\n",
    "    columns = []\n",
    "    \n",
    "    #removing irrelevant columns\n",
    "    for col in data.columns:\n",
    "        if col == \"ZIP Code\"or col == \"ID\":\n",
    "            continue\n",
    "        else:\n",
    "            columns.append(col)\n",
    "    rows = []\n",
    "    cols = []\n",
    "    for dt in range(3):\n",
    "        rows.extend([dt] * 4)\n",
    "        cols.extend(range(4))\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 4, figsize=(11,11))\n",
    "    for i in range(len(columns)):\n",
    "        sbs.histplot(data[columns[i]], ax=axes[rows[i], cols[i]])\n",
    "    \n",
    "    fig.subtitle = (\"Histograms Of Columns in the dataset\")\n",
    "    plt.show()\n",
    "    fig.savefig(\"Visa_For_Lisa_Histogram.png\")\n",
    "print_histograms(data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb43d485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scatter_matrix(dataset):\n",
    "    columns= []\n",
    "    for i in data.columns:\n",
    "        if i == 'ZIP Code' or i == 'ID' :\n",
    "            continue\n",
    "        else:\n",
    "            columns.append(i)\n",
    "    new_data=dataset[columns]\n",
    "    plt.figure(figsize=(10,12))\n",
    "    plot=sbs.heatmap(new_data.corr(), cmap='YlGnBu', annot=True)\n",
    "    plt.title(\"A plot of the Correlation of the Numerical Columns in the Dataset\", fontdict={'fontsize':10,'fontweight':'extra bold','horizontalalignment': 'center'}, y=1.0)\n",
    "    plt.savefig(\"Scatter_Matrix.png\")\n",
    "    plt.show()\n",
    "print_scatter_matrix(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099b69fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GETTING DISTRIBUTION OF AGES\n",
    "\n",
    "Age=data['Age'].value_counts().reset_index(name='Count').sort_values(by=['index']).reset_index(drop=True)\n",
    "Age.rename(columns={'index':'AGE'}, inplace=True)\n",
    "Age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd62040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the ages\n",
    "\n",
    "bn = np.array([22,34, 44, 64,max(Age['AGE'])])\n",
    "Age['AGE_group']=pd.cut(Age['AGE'],bins=bn\n",
    "       , labels=[\"Early Adulthood\", \"Early Middles\", \"Late Middles\",\"Late Adulthood\"])\n",
    "Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abf0d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp = data['Experience'].value_counts().reset_index(name='Number').sort_values(by='index').reset_index(drop=True)\n",
    "Exp.rename(columns={'index': 'Exp_years'}, inplace=True)\n",
    "Exp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f757cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_exp = Exp['Exp_years'].max()\n",
    "bins = np.array([-1, 2, 5, 8, 10, max_exp])\n",
    "labels = [\"Entry_level\", \"Intermediate_level\", \"Experienced_level\", \"Advanced_level\", \"Expert_level\"]\n",
    "\n",
    "Exp['Job_level'] = pd.cut(Exp['Exp_years'], bins=bins, labels=labels)\n",
    "Exp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbda807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_exp=Exp.groupby('Job_level',as_index=False)[['Number']].sum()\n",
    "group_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8292eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.groupby(['Age', 'Personal Loan'])[['Personal Loan']].count().rename(columns={'Personal Loan': 'values_count'}).reset_index()\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3626c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=np.array([22,34, 44, 64,max(Age['AGE'])])\n",
    "data1['Age_group']=pd.cut(data1['Age'],bins=bins\n",
    "       , labels=[\"Early Adulthood\", \"Early Middle Age\", \"Late Middle Age\",\"Late Adulthood\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bab481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f27d549",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = data1.groupby(['Age_group', 'Personal Loan']).agg({'values_count': 'sum'})\n",
    "age['%'] = age.groupby(level=0).apply(lambda x: 100 * x / x.sum()).round(2)\n",
    "age = age.reset_index(level=1).reset_index(level=0)\n",
    "\n",
    "age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960ab30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962bf775",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [str(i) + '%' for i in age['%']]\n",
    "fig = px.bar(\n",
    "age,\n",
    "x='Age_group',\n",
    "y='values_count',\n",
    "color='Personal Loan',\n",
    "barmode='group',\n",
    "text=text,\n",
    "color_discrete_sequence=px.colors.sequential.Viridis\n",
    ")\n",
    "fig.update_layout(\n",
    "plot_bgcolor='rgba(0, 175, 200, 0)',\n",
    "title={\n",
    "'text': 'Distribution of people who accepted and rejected the Loan by Age Groups',\n",
    "'x': 0.9,\n",
    "'y': 0.95,\n",
    "'font_size': 15\n",
    "}\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image('dist_age.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5223e27a",
   "metadata": {},
   "source": [
    "## Distribution By Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86ebc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.groupby(['Income', 'Personal Loan'])[['Personal Loan']].count().rename(columns={'Personal Loan': 'values_count'}).reset_index()\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475a9d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=np.array([0,52.2, 156.6,max(data2['Income'])])\n",
    "data2['income_group']=pd.cut(data2['Income'],bins=bins\n",
    "       , labels=[\"Low Income Class\", \"Middle Income Class\",\"Upper Income Class\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc12ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1384ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "income = data2.groupby(['income_group', 'Personal Loan']).agg({'values_count': 'sum'})\n",
    "income['%'] = income.groupby(level=0).apply(lambda x: 100 * x / float(x.sum())).round(2)\n",
    "income = income.reset_index(level=1).reset_index(level=0)\n",
    "income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe483e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=[str(i)+ '%' for i in income['%']]\n",
    "fig=px.bar(income,x='income_group',y='values_count',color='Personal Loan', barmode='group',text=text,\n",
    "          color_discrete_sequence=px.colors.sequential.Viridis)\n",
    "fig.update_layout({'plot_bgcolor':'rgba(0,175,200,0)'})\n",
    "fig.update_layout({'title':{'text':'Distribution of People who accepted and rejected the Loans by income group',\n",
    "                            'x':0.2, 'y':0.95,\n",
    "                            'font_size':15\n",
    "                           }})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5fd078",
   "metadata": {},
   "source": [
    "## Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16951fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution(cols):\n",
    "    print('Distribution By ' + cols + ':')\n",
    "    data_col = data.groupby([cols, 'Personal Loan'])[['Personal Loan']].count().rename(columns={'Personal Loan': 'values_count'}).reset_index()\n",
    "    data_col.head()\n",
    "    group=data_col.groupby([cols,'Personal Loan']).agg({'values_count':'sum'})\n",
    "    group['%']=group.groupby(level=0).apply(lambda x: 100 * x/float(x.sum())).round(2)\n",
    "    group=group.reset_index(level=1).reset_index(level=0)\n",
    "    print(group)\n",
    "    text=[str(i)+ '%' for i in group['%']]\n",
    "    fig=px.bar(group,x=cols,y='values_count',color='Personal Loan', barmode='group',text=text,\n",
    "              color_discrete_sequence=px.colors.sequential.Viridis)\n",
    "    fig.update_layout({'plot_bgcolor':'rgba(255,99,71,0.05)'})\n",
    "    fig.update_layout({'title':{'text':'Distribution of People who accepted and rejected the Loans by {cols}'.format(cols = cols),\n",
    "                                'x':0.2, 'y':0.95,\n",
    "                                'font_size':12\n",
    "                               }})\n",
    "    fig.show()\n",
    "    \n",
    "columns = ['Family', 'Education', 'Securities Account','CD Account', 'Online', 'CreditCard']\n",
    "for cols in columns:\n",
    "    distribution(cols)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d506cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data0=list(data[data['Personal Loan']== 0]['CCAvg'])\n",
    "data1=list(data[data['Personal Loan']== 1]['CCAvg'])\n",
    "hist_data = [data0, data1]\n",
    "group_labels = ['0','1']\n",
    "colors = ['#333F44', '#37AA9C']\n",
    "\n",
    "# Create distplot with curve_type set to 'normal'\n",
    "fig = ff.create_distplot(hist_data, group_labels,curve_type='normal',colors=colors,histnorm='probability density', show_rug=False)\n",
    "\n",
    "# Add title\n",
    "fig.update_layout(title_text='CCAvg for Customers')\n",
    "fig.update_layout({'plot_bgcolor':'rgba(255,99,71,0.05)'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c4f760",
   "metadata": {},
   "source": [
    "## Initialising Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5334fdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiating the logistic regression\n",
    "log_reg=LogisticRegression()\n",
    "\n",
    "#initiating the naive bayes model\n",
    "naive_bayes=GaussianNB()\n",
    "\n",
    "#initiating the KNN model\n",
    "knn=KNeighborsClassifier(n_neighbors=15)\n",
    "\n",
    "#initializing the the RandomForest model\n",
    "random=RandomForestClassifier(n_estimators=70,oob_score=True,n_jobs=-1,random_state=101,max_features=None,min_samples_leaf=30)\n",
    "\n",
    "#initializing the Support Vector Machine\n",
    "SVM = SVC(kernel=\"linear\",C=0.025, random_state=101)\n",
    "\n",
    "#initializing the Decision Tree\n",
    "dtree=DecisionTreeClassifier(max_depth=10,random_state=101,max_features=None,min_samples_leaf=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d3dea3",
   "metadata": {},
   "source": [
    "## Splitting the data into testing and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a94382",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop('Personal Loan', axis=1)\n",
    "y= data['Personal Loan']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd04cd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = {\n",
    "'Logistic Regression': log_reg,\n",
    "'Naive Bayes': naive_bayes,\n",
    "'KNN': knn,\n",
    "'Random Forests': random,\n",
    "'Support Vector Machine': SVM,\n",
    "'Decision Trees': dtree\n",
    "}\n",
    "\n",
    "evaluations = []\n",
    "\n",
    "for classifier_name, classifier in clf.items():\n",
    "    evals = {}\n",
    "    y_pred = classifier.fit(X_train, y_train).predict(X_test)\n",
    "    evals['Accuracy'] = accuracy_score(y_test, y_pred)\n",
    "    evals['Precision'] = precision_score(y_test, y_pred, pos_label=1)\n",
    "    evals['Recall'] = recall_score(y_test, y_pred, pos_label=1)\n",
    "    evals['F1'] = f1_score(y_test, y_pred, pos_label=1)\n",
    "    evaluations.append(evals)\n",
    "\n",
    "metrics = pd.DataFrame(evaluations, index=['Logistic Regression', 'Naive Bayes', 'KNN', 'Random Forests', 'Support Vector Machine', 'Decision Trees'])\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3cbb8d",
   "metadata": {},
   "source": [
    "from the data above we ca see the Random Forests And Decisions Tree generated the best results.\n",
    "we will try hyperparameters to see if we can get improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bca01ac",
   "metadata": {},
   "source": [
    "## IMPROVING THE RANDOM FOREX MODEL WITH TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7bd133",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [20, 50, 100]\n",
    "min_samples_leaf = [2, 5, 10]\n",
    "max_depth = [3, 5, 7]\n",
    "max_features = ['auto', 'sqrt', 'log2', None]\n",
    "\n",
    "RandomForest_grid_search = GridSearchCV(RandomForestClassifier(),\n",
    "param_grid={'n_estimators': n_estimators,\n",
    "'min_samples_leaf': min_samples_leaf,\n",
    "'max_depth': max_depth,\n",
    "'max_features': max_features})\n",
    "\n",
    "RandomForest_grid_search.fit(X_train, y_train)\n",
    "print(RandomForest_grid_search.best_params_, 'hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898e0f8c",
   "metadata": {},
   "source": [
    "## IMPROVING DECISION TREE WITH TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b9c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [2, 5, 10, None]\n",
    "min_samples_split = [2, 5, 10, None]\n",
    "min_samples_leaf = [1, 5, 7]\n",
    "max_features = [1, 2, 3]\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "param_grid = {\n",
    "'max_depth': max_depth,\n",
    "'min_samples_split': min_samples_split,\n",
    "'min_samples_leaf': min_samples_leaf,\n",
    "'max_features': max_features,\n",
    "'criterion': criterion\n",
    "}\n",
    "\n",
    "DecisionTree_grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid=param_grid)\n",
    "DecisionTree_grid_search.fit(X_train, y_train)\n",
    "print(DecisionTree_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13babf73",
   "metadata": {},
   "source": [
    "after tuning twe will evaluate the model againhe parameters of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c040c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_2 = {\n",
    "'Random Forest': RandomForestClassifier(max_depth=7, max_features='sqrt', min_samples_leaf=2, n_estimators=100),\n",
    "'Decision Trees': DecisionTreeClassifier(criterion='gini', max_depth=None, max_features=3, min_samples_leaf=1, min_samples_split=2)\n",
    "}\n",
    "\n",
    "evaluations2 = []\n",
    "for classifier_name, classifier in clf_2.items():\n",
    "    evals_2 = {}\n",
    "    y_pred = classifier.fit(X_train, y_train).predict(X_test)\n",
    "    evals_2['Accuracy'] = accuracy_score(y_test, y_pred)\n",
    "    evals_2['Precision'] = precision_score(y_test, y_pred, pos_label=1)\n",
    "    evals_2['Recall'] = recall_score(y_test, y_pred, pos_label=1)\n",
    "    evals_2['F1'] = f1_score(y_test, y_pred, pos_label=1)\n",
    "    evaluations2.append(evals_2)\n",
    "\n",
    "metrics2 = pd.DataFrame(evaluations2, index=['Random Forests', 'Decision Trees'])\n",
    "metrics2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab2071a",
   "metadata": {},
   "source": [
    "Based on the above, the Random Forest is the best model for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d260227c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
